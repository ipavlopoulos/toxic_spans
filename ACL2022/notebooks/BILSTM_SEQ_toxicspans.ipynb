{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BILSTM_SEQ.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Install Requirements"
      ],
      "metadata": {
        "id": "LeDBvJ6Q8_-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U \"tensorflow-text==2.8.*\"\n",
        "#!pip install pandas\n",
        "#!pip install scipy\n",
        "#!pip install sklearn"
      ],
      "metadata": {
        "id": "FFnFPMt89DLt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "7Qo4_eCS89kO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tCbD2MfA8d4F"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from ast import literal_eval\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install ToxicSpans"
      ],
      "metadata": {
        "id": "2drz-ui79GPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ipavlopoulos/toxic_spans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzAIp0uY9N08",
        "outputId": "ac59a60a-3532-42c5-e079-5fcb6d7cd876"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'toxic_spans' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Metrics"
      ],
      "metadata": {
        "id": "deDZVOHU9cDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/ipavlopoulos/toxic_spans.git\n",
        "!pip install lime\n",
        "from toxic_spans.SemEval2021.evaluation import semeval2021\n",
        "from toxic_spans.SemEval2021.baselines import models\n",
        "\n",
        "\n",
        "def precision(predictions, gold):\n",
        "  if len(gold) == 0:\n",
        "    return 1. if len(predictions) == 0 else 0.\n",
        "  if len(predictions) == 0:\n",
        "    return 0.\n",
        "  predictions_set = set(predictions)\n",
        "  gold_set = set(gold)\n",
        "  nom = len(predictions_set.intersection(gold_set))\n",
        "  denom = len(predictions_set)\n",
        "  return float(nom)/float(denom)\n",
        "\n",
        "def recall(predictions, gold):\n",
        "  if len(gold) == 0:\n",
        "    return 1. if len(predictions) == 0 else 0.\n",
        "  if len(predictions) == 0:\n",
        "    return 0.\n",
        "  predictions_set = set(predictions)\n",
        "  gold_set = set(gold)\n",
        "  nom = len(predictions_set.intersection(gold_set))\n",
        "  denom = len(gold_set)\n",
        "  return float(nom)/float(denom)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGt9dmJq9T5F",
        "outputId": "8bb536d0-4f94-490a-d70b-6e9f8bba6ef3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lime in /usr/local/lib/python3.7/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lime) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lime) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from lime) (1.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime) (3.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime) (0.18.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lime) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2021.11.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (1.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->lime) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->lime) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method for Preparing the dataset (literal_eval some columns)"
      ],
      "metadata": {
        "id": "FbWUFiMm9tSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(dataset):\n",
        "  dataset.probability = dataset.probability.apply(literal_eval)\n",
        "  dataset.position = dataset.position.apply(literal_eval)\n",
        "  dataset.text = dataset.text.apply(literal_eval)\n",
        "  dataset['type'] = dataset['type'].apply(literal_eval)\n",
        "  dataset.position_probability = dataset.position_probability.apply(literal_eval)\n",
        "  if 'position_lbl'in dataset.columns:\n",
        "    dataset.position_lbl = dataset.position_lbl.apply(literal_eval)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "S1EpflVB9fww"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Align tokens with token labels"
      ],
      "metadata": {
        "id": "eVriqT8D-bD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for each token extract the probabilistic label \n",
        "def extract_xy(data, tokenizer = None):\n",
        "  X = []\n",
        "  y = []\n",
        "  t_of = []\n",
        "  for i in tqdm(range(data.shape[0])):\n",
        "    toks = []\n",
        "    labels = []\n",
        "    offsets = []\n",
        "    (tokens, start_offsets, end_offsets) = tokenizer.tokenize_with_offsets(data.iloc[i].text_of_post)\n",
        "    for j in  range(len(tokens)):\n",
        "      span = []\n",
        "      token = data.iloc[i].text_of_post[start_offsets[j]: end_offsets[j]]\n",
        "      token_offset = [i for i in range(start_offsets[j], end_offsets[j])]\n",
        "      for char_off in token_offset:\n",
        "        if char_off in data.iloc[i].position_probability.keys(): # if in a span\n",
        "          span.append(data.position_probability.iloc[i][char_off])\n",
        "        else: #char not in a span\n",
        "          span.append(0)\n",
        "      labels.append(np.mean(span)) #this token has toxicity = with the mean of its chars\n",
        "      toks.append(token)\n",
        "      offsets.append([i for i in range(start_offsets[j], end_offsets[j])])\n",
        "    y.append(labels)\n",
        "    X.append(toks)\n",
        "    t_of.append(offsets)\n",
        "  return X,y,t_of\n",
        "\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"toxic_spans/ACL2022/data/toxic_spans.csv\")\n",
        "data = prepare_dataset(data)\n",
        "\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "tokenizer = tf_text.UnicodeScriptTokenizer()\n",
        "x, y,t = extract_xy(data, tokenizer)\n",
        "\n",
        "data['tokens'], data['token_labels'], data['token_offsets'] = x, y, t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rtKQZqBYzL9",
        "outputId": "5a3b044d-ca38-4c87-9716-c8aa4eee4a55"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11006/11006 [35:22<00:00,  5.19it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train BILSTM_SEQ on a Random Train/dev/Test split"
      ],
      "metadata": {
        "id": "VyoamvBVPRMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from toxic_spans.ACL2022.models.seq import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import *\n",
        "\n",
        "train, dev = train_test_split(data, test_size = 0.2, random_state = 0)\n",
        "dev, test = train_test_split(dev, test_size = 0.5, random_state = 0)\n",
        "train, dev, test = train.reset_index(), dev.reset_index(), test.reset_index()\n",
        "\n",
        "model = BILSTM_SEQ(patience = 5)\n",
        "hs = model.fit(train.tokens, train.token_labels, dev.tokens, dev.token_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr7DxzT6-oF7",
        "outputId": "2b81405f-5397-40eb-d7b5-575d06e74154"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size:  31873\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 128)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 128, 200)          6374600   \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 128, 200)          0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128, 256)         336896    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " layer_normalization (LayerN  (None, 128, 256)         512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 128, 1)           257       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " tf.compat.v1.squeeze (TFOpL  None                     0         \n",
            " ambda)                                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,712,265\n",
            "Trainable params: 6,712,265\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "69/69 [==============================] - 15s 74ms/step - loss: 0.0163 - MSE: 0.0163 - MAE: 0.0482 - MSLE: 0.0069 - val_loss: 0.0042 - val_MSE: 0.0042 - val_MAE: 0.0230 - val_MSLE: 0.0028\n",
            "Epoch 2/1000\n",
            "69/69 [==============================] - 2s 32ms/step - loss: 0.0037 - MSE: 0.0037 - MAE: 0.0211 - MSLE: 0.0024 - val_loss: 0.0040 - val_MSE: 0.0040 - val_MAE: 0.0238 - val_MSLE: 0.0027\n",
            "Epoch 3/1000\n",
            "69/69 [==============================] - 2s 32ms/step - loss: 0.0032 - MSE: 0.0032 - MAE: 0.0196 - MSLE: 0.0021 - val_loss: 0.0040 - val_MSE: 0.0040 - val_MAE: 0.0234 - val_MSLE: 0.0028\n",
            "Epoch 4/1000\n",
            "69/69 [==============================] - 2s 31ms/step - loss: 0.0028 - MSE: 0.0028 - MAE: 0.0188 - MSLE: 0.0018 - val_loss: 0.0041 - val_MSE: 0.0041 - val_MAE: 0.0233 - val_MSLE: 0.0028\n",
            "Epoch 5/1000\n",
            "69/69 [==============================] - 2s 31ms/step - loss: 0.0026 - MSE: 0.0026 - MAE: 0.0183 - MSLE: 0.0016 - val_loss: 0.0042 - val_MSE: 0.0042 - val_MAE: 0.0240 - val_MSLE: 0.0029\n",
            "Epoch 6/1000\n",
            "69/69 [==============================] - 2s 32ms/step - loss: 0.0025 - MSE: 0.0025 - MAE: 0.0176 - MSLE: 0.0015 - val_loss: 0.0041 - val_MSE: 0.0041 - val_MAE: 0.0230 - val_MSLE: 0.0027\n",
            "Epoch 7/1000\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0023 - MSE: 0.0023 - MAE: 0.0168 - MSLE: 0.0014Restoring model weights from the end of the best epoch: 2.\n",
            "69/69 [==============================] - 2s 32ms/step - loss: 0.0023 - MSE: 0.0023 - MAE: 0.0168 - MSLE: 0.0014 - val_loss: 0.0041 - val_MSE: 0.0041 - val_MAE: 0.0233 - val_MSLE: 0.0028\n",
            "Epoch 7: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ],
      "metadata": {
        "id": "SC4LCm1yi-IF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_offsets = model.get_toxic_offsets(test.tokens, 0.5)\n",
        "pred_char_offsets = model.get_toxic_char_offsets(test.token_offsets, pred_offsets)\n",
        "\n",
        "f1 = np.mean([semeval2021.f1(p,g) for p,g in list(zip(pred_char_offsets, test.position))])\n",
        "pr = np.mean([precision(p,g) for p,g in list(zip(pred_char_offsets, test.position))])\n",
        "rec = np.mean([recall(p,g) for p,g in list(zip(pred_char_offsets, test.position))])\n",
        "\n",
        "print(\"F1: \",f1)\n",
        "print(\"Recall: \",rec)\n",
        "print(\"Precision: \",pr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANWUOwPsO712",
        "outputId": "c73b4c75-9ad8-4622-dbf6-6f53402809e2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1:  0.5785078652531558\n",
            "Recall:  0.5809530643267494\n",
            "Precision:  0.585381981022308\n"
          ]
        }
      ]
    }
  ]
}